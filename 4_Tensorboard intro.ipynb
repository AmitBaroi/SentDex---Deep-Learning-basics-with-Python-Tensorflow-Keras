{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Cats-vs-Dogs-CNN-64x2-{}\".format(time.time())\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image matrices\n",
    "pickle_in = open(\"Data\\X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "# Scaling feature\n",
    "X = X/255\n",
    "\n",
    "# Loading image labels\n",
    "pickle_in = open(\"Data\\y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Hidden layer 1\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Hidden layer 2\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 141s 8ms/step - loss: 0.6527 - acc: 0.6038 - val_loss: 0.5971 - val_acc: 0.6855\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 177s 10ms/step - loss: 0.5572 - acc: 0.7183 - val_loss: 0.5266 - val_acc: 0.7456\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 178s 10ms/step - loss: 0.5006 - acc: 0.7569 - val_loss: 0.5456 - val_acc: 0.7313\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 183s 10ms/step - loss: 0.4630 - acc: 0.7785 - val_loss: 0.4771 - val_acc: 0.7699\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 184s 11ms/step - loss: 0.4229 - acc: 0.8017 - val_loss: 0.4739 - val_acc: 0.7742\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 196s 11ms/step - loss: 0.3758 - acc: 0.8326 - val_loss: 0.4876 - val_acc: 0.7704\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 194s 11ms/step - loss: 0.3245 - acc: 0.8565 - val_loss: 0.5307 - val_acc: 0.7698\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 191s 11ms/step - loss: 0.2721 - acc: 0.8850 - val_loss: 0.5233 - val_acc: 0.7847\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 195s 11ms/step - loss: 0.2127 - acc: 0.9138 - val_loss: 0.6028 - val_acc: 0.7638\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 193s 11ms/step - loss: 0.1631 - acc: 0.9367 - val_loss: 0.6704 - val_acc: 0.7731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc2782e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "As our model runs (or after it finishes) we can obseve its accuracy and loss (cost) for both training and validation.\n",
    "\n",
    "We should open a terminal window in our directory that contains the 'logs' folder and input the following command \n",
    "> `tensorboard --logdir=logs/`\n",
    "\n",
    "We can see that after removing the dense layer (hidden layer 2), the validation accuracy increased and the validation loss decreased, which are good indications that this design is better.\n",
    "\n",
    "So it seems removing the dense layer improved our model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
