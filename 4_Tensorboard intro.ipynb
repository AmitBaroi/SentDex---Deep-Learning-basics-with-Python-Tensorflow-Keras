{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging this model instance\n",
    "NAME = \"Cats-vs-Dogs-CNN-64x2-{}\".format(time.time())\n",
    "# Tensorboard callback\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image matrices\n",
    "pickle_in = open(\"Data\\X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "# Scaling feature\n",
    "X = X/255\n",
    "\n",
    "# Loading image labels\n",
    "pickle_in = open(\"Data\\y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Hidden layer 1\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Hidden layer 2\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(64))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 141s 8ms/step - loss: 0.6281 - acc: 0.6361 - val_loss: 0.5651 - val_acc: 0.7153\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 160s 9ms/step - loss: 0.5409 - acc: 0.7304 - val_loss: 0.5407 - val_acc: 0.7312\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 170s 10ms/step - loss: 0.4996 - acc: 0.7593 - val_loss: 0.5065 - val_acc: 0.7592\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 169s 10ms/step - loss: 0.4754 - acc: 0.7757 - val_loss: 0.4982 - val_acc: 0.7596\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 171s 10ms/step - loss: 0.4547 - acc: 0.7852 - val_loss: 0.4642 - val_acc: 0.7829\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 171s 10ms/step - loss: 0.4333 - acc: 0.8004 - val_loss: 0.4704 - val_acc: 0.7830\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 172s 10ms/step - loss: 0.4166 - acc: 0.8116 - val_loss: 0.5039 - val_acc: 0.7650\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 173s 10ms/step - loss: 0.4015 - acc: 0.8179 - val_loss: 0.4396 - val_acc: 0.7954\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 172s 10ms/step - loss: 0.3816 - acc: 0.8265 - val_loss: 0.4480 - val_acc: 0.7942\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 173s 10ms/step - loss: 0.3689 - acc: 0.8349 - val_loss: 0.4349 - val_acc: 0.8014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc25e208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "As our model runs (or after it finishes) we can obseve its accuracy and loss (cost) for both training and validation.\n",
    "\n",
    "We should open a terminal window in our directory that contains the 'logs' folder and input the following command \n",
    "> `tensorboard --logdir=logs/`\n",
    "\n",
    "We can see that after removing the dense layer (hidden layer 2), the validation accuracy increased and the validation loss decreased, which are good indications that this design is better.\n",
    "\n",
    "So it seems removing the dense layer improved our model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
