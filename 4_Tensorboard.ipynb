{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Cats-vs-Dogs-CNN-64x2-{}\".format(time.time())\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image matrices\n",
    "pickle_in = open(\"Data\\X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "# Scaling feature\n",
    "X = X/255\n",
    "\n",
    "# Loading image labels\n",
    "pickle_in = open(\"Data\\y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Hidden layer 1\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Hidden layer 2\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(64))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 147s 8ms/step - loss: 0.6223 - acc: 0.6465 - val_loss: 0.5571 - val_acc: 0.7304\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 174s 10ms/step - loss: 0.5285 - acc: 0.7386 - val_loss: 0.5240 - val_acc: 0.7469\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 170s 10ms/step - loss: 0.4887 - acc: 0.7672 - val_loss: 0.4832 - val_acc: 0.7737\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 183s 10ms/step - loss: 0.4676 - acc: 0.7801 - val_loss: 0.4734 - val_acc: 0.7791\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 179s 10ms/step - loss: 0.4455 - acc: 0.7938 - val_loss: 0.4976 - val_acc: 0.7588\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 172s 10ms/step - loss: 0.4230 - acc: 0.8070 - val_loss: 0.4734 - val_acc: 0.7805\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 173s 10ms/step - loss: 0.4092 - acc: 0.8165 - val_loss: 0.4782 - val_acc: 0.7778\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 172s 10ms/step - loss: 0.3875 - acc: 0.8269 - val_loss: 0.4654 - val_acc: 0.7885\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 173s 10ms/step - loss: 0.3685 - acc: 0.8383 - val_loss: 0.4624 - val_acc: 0.7908\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 171s 10ms/step - loss: 0.3604 - acc: 0.8418 - val_loss: 0.4497 - val_acc: 0.7982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xbe86128>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "As our model runs (or after it finishes) we can obseve its accuracy and loss (cost) for both training and validation.\n",
    "\n",
    "We should open a terminal window in our directory that contains the 'logs' folder and input the following command `tensorboard --logdir=logs/`\n",
    "\n",
    "We can see that after removing the dense layer (hidden layer 2), the validation accuracy increased and the validation loss decreased, which are good indications that this design is better.\n",
    "\n",
    "So it seems removing the dense layer improved our model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
